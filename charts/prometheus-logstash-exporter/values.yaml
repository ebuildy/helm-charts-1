## number of exporter instances
##
replicaCount: 1

## restart policy for all containers
##
restartPolicy: Always

image:
  repository: alxrem/prometheus-logstash-exporter
  tag: 0.7.0
  pullPolicy: IfNotPresent
  pullSecret: ""

## Set enabled to false if you don't want securityContext
## in your Deployment.
## The below values are the default for kubernetes.
## Openshift won't deploy with runAsUser: 1000 without additional permissions.
securityContext:
  enabled: true  # Should be set to false when running on OpenShift
  runAsUser: 1000

log:
  format: logfmt
  level: info

resources: {}
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
  # limits:
  #   cpu: 100m
  #   memory: 128Mi

priorityClassName: ""

nodeSelector: {}

tolerations: []

podAnnotations: {}

podLabels: {}

affinity: {}

service:
  type: ClusterIP
  httpPort: 9108
  metricsPort:
    name: http
  annotations: {}
  labels: {}

## Extra environment variables that will be passed into the exporter pod
## example:
## env:
##   KEY_1: value1
##   KEY_2: value2
env: {}

## The name of a secret in the same kubernetes namespace which contain values to be added to the environment
## This can be useful for auth tokens, etc
envFromSecret: ""

## A list of environment variables from secret refs that will be passed into the exporter pod
## example:
## This will set ${ES_PASSWORD} to the 'password' key from the 'my-secret' secret
## extraEnvSecrets:
##   ES_PASSWORD:
##     secret: my-secret
##     key: password
extraEnvSecrets: {}

# A list of secrets and their paths to mount inside the pod
# This is useful for mounting certificates for security
secretMounts: []
#  - name: elastic-certs
#    secretName: elastic-certs
#    path: /ssl

logstash:
  host: localhost
  port: 9600

web:
  ## Path under which to expose metrics.
  ##
  path: /metrics

serviceMonitor:
  ## If true, a ServiceMonitor CRD is created for a prometheus operator
  ## https://github.com/coreos/prometheus-operator
  ##
  enabled: false
  #  namespace: monitoring
  labels: {}
  interval: 10s
  scrapeTimeout: 10s
  scheme: http
  relabelings: []
  targetLabels: []
  metricRelabelings: []
  sampleLimit: 0

prometheusRule:
  ## If true, a PrometheusRule CRD is created for a prometheus operator
  ## https://github.com/coreos/prometheus-operator
  ##
  ## The rules will be processed as Helm template, allowing to set variables in them.
  enabled: false
  #  namespace: monitoring
  labels: {}
  rules: []
    # - record: elasticsearch_filesystem_data_used_percent
    #   expr: |
    #     100 * (elasticsearch_filesystem_data_size_bytes{service="{{ template "logstash-exporter.fullname" . }}"} - elasticsearch_filesystem_data_free_bytes{service="{{ template "logstash-exporter.fullname" . }}"})
    #     / elasticsearch_filesystem_data_size_bytes{service="{{ template "logstash-exporter.fullname" . }}"}
    # - record: elasticsearch_filesystem_data_free_percent
    #   expr: 100 - elasticsearch_filesystem_data_used_percent{service="{{ template "logstash-exporter.fullname" . }}"}
    # - alert: ElasticsearchTooFewNodesRunning
    #   expr: elasticsearch_cluster_health_number_of_nodes{service="{{ template "logstash-exporter.fullname" . }}"} < 3
    #   for: 5m
    #   labels:
    #     severity: critical
    #   annotations:
    #     description: There are only {{ "{{ $value }}" }} < 3 ElasticSearch nodes running
    #     summary: ElasticSearch running on less than 3 nodes
    # - alert: ElasticsearchHeapTooHigh
    #   expr: |
    #     elasticsearch_jvm_memory_used_bytes{service="{{ template "logstash-exporter.fullname" . }}", area="heap"} / elasticsearch_jvm_memory_max_bytes{service="{{ template "logstash-exporter.fullname" . }}", area="heap"}
    #     > 0.9
    #   for: 15m
    #   labels:
    #     severity: critical
    #   annotations:
    #     description: The heap usage is over 90% for 15m
    #     summary: ElasticSearch node {{ "{{ $labels.node }}" }} heap usage is high

# Create a service account
# To use a service account not handled by the chart, set the name here
# and set create to false
serviceAccount:
  create: false
  name: default

# Creates a PodSecurityPolicy and the role/rolebinding
# allowing the serviceaccount to use it
podSecurityPolicies:
  enabled: false
